{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train-val-split-iteration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPprRsV+ySWbP5KhRjLZ1dQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viveksahukar/sih/blob/main/train_val_split_iteration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEZAwiY6ZzPR"
      },
      "source": [
        "# This notebook details how the train-val splits are done and changing random seed will produce different combinations of train-val datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "675PJ9O3Z3oI"
      },
      "source": [
        "random_state = 3 # Set random state\n",
        "from vs165_modules import * # Load required libraries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFQYODLMZ3lg"
      },
      "source": [
        "# Now dataframes where the slices for each PatientID have been selected\n",
        "ax_common = pd.read_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/ax_common.csv')\n",
        "cor_common_1 = pd.read_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_common_1.csv')\n",
        "cor_common_2= pd.read_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_common_2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_hDDlDzZ3i3"
      },
      "source": [
        "# Dividing into train/ val/ test split for each pos / neg case \n",
        "# so same ratio is maintained in train / val /test split \n",
        "ax_pos = ax_common[ax_common.label == 1]\n",
        "ax_neg = ax_common[ax_common.label == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfqhmpuXZ3f4"
      },
      "source": [
        "# positive cases: train(47) + val1(30) + val2(26) + test(52)= 155\n",
        "# negative cases: train(82) + val1(54) + val2(45) + test(92) = 273\n",
        "ax_pos_train = ax_pos.iloc[:47, :]\n",
        "ax_pos_val_1 = ax_pos.iloc[47:77, :]\n",
        "ax_pos_val_2 = ax_pos.iloc[77:103, :]\n",
        "ax_pos_test = ax_pos.iloc[103:, :]\n",
        "\n",
        "ax_neg_train = ax_neg.iloc[:82, :]\n",
        "ax_neg_val_1 = ax_neg.iloc[82:136, :]\n",
        "ax_neg_val_2 = ax_neg.iloc[136:181, :]\n",
        "ax_neg_test = ax_neg.iloc[181:, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Oj2-r3vaAar"
      },
      "source": [
        "# Start here for new iteration of train / test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJWSw8tVapHU"
      },
      "source": [
        "ax_pos = pd.concat([ax_pos_train, ax_pos_val_1]) # or concat with ax_pos_val_1\n",
        "ax_neg = pd.concat([ax_neg_train, ax_neg_val_1]) # or concat with ax_neg_val_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9K7hL4eapNG"
      },
      "source": [
        "ax_pos = ax_pos.sample(frac=1, random_state=random_state)\n",
        "ax_neg = ax_neg.sample(frac=1, random_state=random_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqz25K_YapP4"
      },
      "source": [
        "# Now dividing into axial data into 80/20 train/val split if included val1\n",
        "ax_pos_train_new = ax_pos.iloc[:62, :]\n",
        "ax_pos_val_new = ax_pos.iloc[62:, :]\n",
        "ax_neg_train_new = ax_neg.iloc[:109, :]\n",
        "ax_neg_val_new = ax_neg.iloc[109:, :]\n",
        "\n",
        "# Now dividing into axial data into 80/20 train/val split if included val2\n",
        "# ax_pos_train_new = ax_pos.iloc[:58, :]\n",
        "# ax_pos_val_new = ax_pos.iloc[58:, :]\n",
        "# ax_neg_train_new = ax_neg.iloc[:101, :]\n",
        "# ax_neg_val_new = ax_neg.iloc[101:, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzH1nm4_apTR"
      },
      "source": [
        "ax_train_new = pd.concat([ax_pos_train_new, ax_neg_train_new])\n",
        "ax_val_new = pd.concat([ax_pos_val_new, ax_neg_val_new])\n",
        "ax_test_new = pd.concat([ax_pos_val_2, ax_neg_val_2]) # change between val_1 and val_2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze7zSYEDayYE"
      },
      "source": [
        "# Saving axial train - val datasets to be used in model building later\n",
        "ax_train_new.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/ax_train_new.csv', index=False)\n",
        "ax_val_new.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/ax_val_new.csv', index=False)\n",
        "ax_test_new.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/ax_test_new.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neW9dNdaayVH"
      },
      "source": [
        "# checking if any duplicate patient ID across train / val split in axial slices ... all good\n",
        "check_duplicate(ax_train_new, ax_test_new)\n",
        "check_duplicate(ax_val_new, ax_test_new)\n",
        "check_duplicate(ax_train_new, ax_val_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RamWJQN-aySC"
      },
      "source": [
        "# extract the PatientID from train / val datasets from axial dataframe\n",
        "pid_ax_train = ax_train_new[['PatientID']] # double [[]] to make it dataframe not series\n",
        "pid_ax_val = ax_val_new[['PatientID']]\n",
        "pid_ax_test = ax_test_new[['PatientID']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqqqLsNNa46V"
      },
      "source": [
        "# Now splitting coronal 1 dataset  using same train/test split as axial\n",
        "cor_train_1 = cor_common_1.merge(pid_ax_train, how='right')\n",
        "cor_val_1 = cor_common_1.merge(pid_ax_val, how='right')\n",
        "cor_test_1 = cor_common_1.merge(pid_ax_test, how='right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqqb_8PcayPB"
      },
      "source": [
        "# Now splitting coronal 2 dataset using same train/test split as axial\n",
        "cor_train_2 = cor_common_2.merge(pid_ax_train, how='right')\n",
        "cor_val_2 = cor_common_2.merge(pid_ax_val, how='right')\n",
        "cor_test_2 = cor_common_2.merge(pid_ax_test, how='right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP_kjlBja5SB"
      },
      "source": [
        "# checking if any duplicate patient ID across train / val split in coronal slices ... all good\n",
        "check_duplicate(cor_train_1, cor_test_1)\n",
        "check_duplicate(cor_val_1, cor_test_1)\n",
        "check_duplicate(cor_train_1, cor_val_1)\n",
        "check_duplicate(cor_train_2, cor_test_2)\n",
        "check_duplicate(cor_val_2, cor_test_2)\n",
        "check_duplicate(cor_train_2, cor_val_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYpDjnCrayMU"
      },
      "source": [
        "# Saving coronal train - val datasets to be used in model building later\n",
        "cor_train_1.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_train_1.csv', index=False)\n",
        "cor_val_1.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_val_1.csv', index=False)\n",
        "cor_test_1.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_test_1.csv', index=False)\n",
        "cor_train_2.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_train_2.csv', index=False)\n",
        "cor_val_2.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_val_2.csv', index=False)\n",
        "cor_test_2.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_test_2.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lif6Vr3nayEM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}