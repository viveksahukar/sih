{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_build_train_results.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJFX3Ct7gc87EFHj7IIts6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viveksahukar/sih/blob/main/model_build_train_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5ejz_ESbkl6"
      },
      "source": [
        "# This notebook details how the 3 CNN are trained on 1 Axial and 2 coronal slices, Dicom files are directly fed to CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tW9gw0nbqc4"
      },
      "source": [
        "random_state = 3 # Set random state\n",
        "from vs165_modules import * # Load required libraries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k25QC89Bb2n7"
      },
      "source": [
        "# Running model on axial slices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N945Aq31brjV"
      },
      "source": [
        "# Set device\n",
        "train_on_gpu = cuda.is_available()\n",
        "device = torch.device(\"cuda\" if train_on_gpu else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJY9bAdvbrld"
      },
      "source": [
        "# Set hyperparameters for axial model\n",
        "n_classes = 2 # 2 classes positive and negative\n",
        "learning_rate_ax = 1e-5 \n",
        "batch_size_ax = 10 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uuAevMybrng"
      },
      "source": [
        "ax_train_dataset = DicomDataset('ax_train_new.csv')\n",
        "ax_valid_dataset = DicomDataset('ax_val_new.csv')\n",
        "ax_test_dataset = DicomDataset('ax_test_new.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPH6Kjmpbrpu"
      },
      "source": [
        "# train_set, valid_set = torch.utils.data.random_split(dataset , [149, 64])\n",
        "ax_train_loader = DataLoader(dataset=ax_train_dataset, batch_size=batch_size_ax, shuffle=True)\n",
        "ax_valid_loader = DataLoader(dataset=ax_valid_dataset, batch_size=batch_size_ax, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MaSGIBZbrr9"
      },
      "source": [
        "model_ax = torchvision.models.resnet50(pretrained=True)\n",
        "\n",
        "n_inputs_ax = model_ax.fc.in_features\n",
        "\n",
        "\n",
        "model_ax.fc = nn.Sequential(\n",
        "                      nn.Linear(n_inputs_ax, 256), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, n_classes),                   \n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model_ax.parameters(), lr=learning_rate_ax)\n",
        "\n",
        "save_file_name = f'resnet50-transfer-ax.pt'\n",
        "checkpoint_path = f'resnet50-transfer-ax.pth'\n",
        "\n",
        "model_ax.to(device);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbDcq6tubruG"
      },
      "source": [
        "model_ax, history_ax = model_train(\n",
        "    model_ax,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    ax_train_loader,\n",
        "    ax_valid_loader,\n",
        "    save_file_name=save_file_name,\n",
        "    max_epochs_stop=50,\n",
        "    n_epochs=50,\n",
        "    print_every=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vd4g5bBbrwg"
      },
      "source": [
        "train_loader_ax = DataLoader(dataset=ax_train_dataset, batch_size=1, shuffle=True)\n",
        "valid_loader_ax = DataLoader(dataset=ax_valid_dataset, batch_size=1, shuffle=True)\n",
        "test_loader_ax = DataLoader(dataset=ax_test_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "df_pred_ax_train = model_eval(model_ax, train_loader_ax)\n",
        "df_pred_ax_valid = model_eval(model_ax, valid_loader_ax)\n",
        "df_pred_ax_test = model_eval(model_ax, test_loader_ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwtnPZ82brzH"
      },
      "source": [
        "loss_accuracy(history_ax, 'Axial')\n",
        "roc_pr(df_pred_ax_valid, 'Axial', 'Valid Set')\n",
        "roc_pr(df_pred_ax_test, 'Axial', 'Test Set')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzz6ZeFXcKJ9"
      },
      "source": [
        "# Now training model on coronal slices "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNDP_aTbbr6C"
      },
      "source": [
        "cor_1_train_dataset = DicomDataset('cor_val_1.csv')\n",
        "cor_1_test_dataset = DicomDataset('cor_test_1.csv')\n",
        "cor_2_train_dataset = DicomDataset('cor_train_2.csv')\n",
        "cor_2_valid_dataset = DicomDataset('cor_val_2.csv')\n",
        "cor_2_test_dataset = DicomDataset('cor_test_2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYAhXrgVbr77"
      },
      "source": [
        "n_classes = 2\n",
        "learning_rate_cor = 1e-5\n",
        "batch_size_cor = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVf20w5ubr9_"
      },
      "source": [
        "# train_set, valid_set = torch.utils.data.random_split(dataset , [149, 64])\n",
        "cor_1_train_loader = DataLoader(dataset=cor_1_train_dataset, batch_size=batch_size_cor, shuffle=True)\n",
        "cor_1_valid_loader = DataLoader(dataset=cor_1_valid_dataset, batch_size=batch_size_cor, shuffle=True)\n",
        "cor_1_test_loader = DataLoader(dataset=cor_1_test_dataset, batch_size=batch_size_cor, shuffle=True)\n",
        "cor_2_train_loader = DataLoader(dataset=cor_2_train_dataset, batch_size=batch_size_cor, shuffle=True)\n",
        "cor_2_valid_loader = DataLoader(dataset=cor_2_valid_dataset, batch_size=batch_size_cor, shuffle=True)\n",
        "cor_2_test_loader = DataLoader(dataset=cor_2_test_dataset, batch_size=batch_size_cor, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBfAWpKJbsAF"
      },
      "source": [
        "model_cor_1 = torchvision.models.resnet50(pretrained=True)\n",
        "n_inputs_cor_1 = model_cor_1.fc.in_features\n",
        "model_cor_1.fc = nn.Sequential(\n",
        "                      nn.Linear(n_inputs_cor_1, 256), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, n_classes),                   \n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "model_cor_2 = torchvision.models.resnet50(pretrained=True)\n",
        "n_inputs_cor_2 = model_cor_2.fc.in_features\n",
        "model_cor_2.fc = nn.Sequential(\n",
        "                      nn.Linear(n_inputs_cor_2, 256), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, n_classes),                   \n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "model_cor_1.to(device);\n",
        "model_cor_2.to(device);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtiXJ6ZjcWbt"
      },
      "source": [
        "## Training model on coronal slices 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKJYuRP_cRnk"
      },
      "source": [
        "train_on_gpu = cuda.is_available()\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model_cor_1.parameters(), lr=learning_rate_cor)\n",
        "\n",
        "save_file_name = f'resnet50-transfer-cor-1.pt'\n",
        "checkpoint_path = f'resnet50-transfer-cor-1.pth'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1PAy-djcRj2"
      },
      "source": [
        "model_cor_1, history_cor_1 = model_train(\n",
        "    model_cor_1,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    cor_1_train_loader,\n",
        "    cor_1_valid_loader,\n",
        "    save_file_name=save_file_name,\n",
        "    max_epochs_stop=50,\n",
        "    n_epochs=50,\n",
        "    print_every=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXdhprYTcRf0"
      },
      "source": [
        "train_loader_cor_1 = DataLoader(dataset=cor_1_train_dataset, batch_size=1, shuffle=True)\n",
        "valid_loader_cor_1 = DataLoader(dataset=cor_1_valid_dataset, batch_size=1, shuffle=True)\n",
        "test_loader_cor_1 = DataLoader(dataset=cor_1_test_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "df_pred_cor_1_train = model_eval(model_cor_1, train_loader_cor_1)\n",
        "df_pred_cor_1_valid = model_eval(model_cor_1, valid_loader_cor_1)\n",
        "df_pred_cor_1_test = model_eval(model_cor_1, test_loader_cor_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4nt2Xo9cRcO"
      },
      "source": [
        "loss_accuracy(history_cor_1, 'Coronal 1')\n",
        "roc_pr(df_pred_cor_1_valid, 'Coronal 1', 'Valid Set')\n",
        "roc_pr(df_pred_cor_1_test, 'Coronal 1', 'Test Set')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJJt7NBAckMc"
      },
      "source": [
        "## Training model on coronal slices 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40KwYT13cjap"
      },
      "source": [
        "train_on_gpu = cuda.is_available()\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model_cor_2.parameters(), lr=learning_rate_cor)\n",
        "\n",
        "save_file_name = f'resnet50-transfer-cor-2.pt'\n",
        "checkpoint_path = f'resnet50-transfer-cor-2.pth'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weXPOHmtcRYb"
      },
      "source": [
        "model_cor_2, history_cor_2 = model_train(\n",
        "    model_cor_2,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    cor_2_train_loader,\n",
        "    cor_2_valid_loader,\n",
        "    save_file_name=save_file_name,\n",
        "    max_epochs_stop=50,\n",
        "    n_epochs=50,\n",
        "    print_every=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BVynkN0cRUo"
      },
      "source": [
        "train_loader_cor_2 = DataLoader(dataset=cor_2_train_dataset, batch_size=1, shuffle=True)\n",
        "valid_loader_cor_2 = DataLoader(dataset=cor_2_valid_dataset, batch_size=1, shuffle=True)\n",
        "test_loader_cor_2 = DataLoader(dataset=cor_2_test_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "df_pred_cor_2_train = model_eval(model_cor_2, train_loader_cor_2)\n",
        "df_pred_cor_2_valid = model_eval(model_cor_2, valid_loader_cor_2)\n",
        "df_pred_cor_2_test = model_eval(model_cor_2, test_loader_cor_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yRWnGvPcRRN"
      },
      "source": [
        "loss_accuracy(history_cor_2, 'Coronal 2')\n",
        "roc_pr(df_pred_cor_2_valid, 'Coronal 2', 'Valid Set')\n",
        "roc_pr(df_pred_cor_2_test, 'Coronal 2', 'Test Set')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R0eoam7czty"
      },
      "source": [
        "## Ensembling the above 3 models using logistic regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZI-sJdScy3G"
      },
      "source": [
        "df_pred_train = df_pred(df_pred_ax_train, df_pred_cor_1_train, df_pred_cor_2_train)\n",
        "df_pred_valid = df_pred(df_pred_ax_valid, df_pred_cor_1_valid, df_pred_cor_2_valid)\n",
        "df_pred_test = df_pred(df_pred_ax_test, df_pred_cor_1_test, df_pred_cor_2_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63JsCKBgcRNK"
      },
      "source": [
        "X_train = df_pred_train[['p_ax', 'p_cor_1', 'p_cor_2']]\n",
        "y_train = df_pred_train['y_true']\n",
        "\n",
        "X_valid = df_pred_valid[['p_ax', 'p_cor_1', 'p_cor_2']]\n",
        "y_valid = df_pred_valid['y_true']\n",
        "\n",
        "X_test = df_pred_test[['p_ax', 'p_cor_1', 'p_cor_2']]\n",
        "y_test = df_pred_test['y_true']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzT1cQHZcRJU"
      },
      "source": [
        "clf = LogisticRegression(random_state=random_state).fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7OhODiXcRF1"
      },
      "source": [
        "# prob score from logistic regression model\n",
        "p_lgr_valid = clf.predict_proba(X_valid)[:, 1]\n",
        "p_lgr_test = clf.predict_proba(X_test)[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww8bHmrzcRCn"
      },
      "source": [
        "df_pred_valid['prob'] = p_lgr_valid\n",
        "df_pred_test['prob'] = p_lgr_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kEDIXlVcQ_W"
      },
      "source": [
        "roc_pr(df_pred_valid, 'Ensemble', 'Valid Set')\n",
        "roc_pr(df_pred_test, 'Ensemble', 'Test Set')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}