{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dicom_to_np_array.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOX9JCLxrI1Ay9NI4dHQdu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viveksahukar/sih/blob/main/dicom_to_np_array.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ0-3ZhTULmg"
      },
      "source": [
        "# This notebook details how the numpy array are extracted from Dicom files to be fed directly to CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xuBsOIFUNov"
      },
      "source": [
        "# Import required libraries\n",
        "from vs165_modules import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDkaXbAyUZks"
      },
      "source": [
        "## Reading axial slices first..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRNxe3fZUWI9"
      },
      "source": [
        "# Reading the csv file\n",
        "# use r string in file path since space in file folder name\n",
        "ax = pd.read_csv(r\"/storage/vs165-projects/Pro00103719 - SIH deep learning/data_ax_cor/data_ax/ax_t1spgr+c_series_master_copy.csv\")\n",
        "ax['label'] = np.where(ax['dirpath'].str.contains('Positive', case=False, regex=True), 1, 0)\n",
        "\n",
        "ax.rename(columns={'dirpath':'fpath'}, inplace=True)\n",
        "ax.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SppsIQ2PUjj3"
      },
      "source": [
        "ax_target_slice = partial(target_slice, targ_pct=0.7)\n",
        "ax['targ_ax'] = ax['fpath'].map(ax_target_slice)\n",
        "ax['full_fpath'] = ax['fpath'] + '/' + ax['targ_ax']\n",
        "ax.drop(columns=['fpath', 'targ_ax'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L38U9ohJUjnL"
      },
      "source": [
        "# Saving ax_new to a dataframe and then csv, so all steps till here need not be repeated\n",
        "ax.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/ax.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgJtH3eZUtX_"
      },
      "source": [
        "## Now reading coronal slices - similar method as for axial slices...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVMjZuYkUjs9"
      },
      "source": [
        "# Reading the csv file\n",
        "# use r string in file path since space in file folder name\n",
        "cor = pd.read_csv(r\"/storage/vs165-projects/Pro00103719 - SIH deep learning/data_ax_cor/data_cor/cor_t1spgr+c_series_master_copy.csv\")\n",
        "cor['label'] = np.where(cor['dirpath'].str.contains('Positive', case=False, regex=True), 1, 0)\n",
        "\n",
        "cor.rename(columns={'dirpath':'fpath'}, inplace=True)\n",
        "cor.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAQ8TKu8Ujvm"
      },
      "source": [
        "cor_1 = cor.copy() # Making copy of the coronal slices dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMzwACPgUjym"
      },
      "source": [
        "# Extracting coronal slice 1\n",
        "cor_1_target_slice = partial(target_slice, targ_pct=0.3)\n",
        "cor_1['targ_ax'] = cor_1['fpath'].map(cor_1_target_slice)\n",
        "cor_1['full_fpath'] = cor_1['fpath'] + '/' + cor_1['targ_ax']\n",
        "cor_1.drop(columns=['fpath', 'targ_ax'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP0K65OhUj1m"
      },
      "source": [
        "# Saving ax_new to a dataframe and then csv, so all steps till here need not be repeated\n",
        "cor_1.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_1.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyUZr020Uj4z"
      },
      "source": [
        "cor_1.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykXI1mIsUj7z"
      },
      "source": [
        "cor_2 = cor.copy() # Making another copy of coronal slices dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdEycO_cUj-v"
      },
      "source": [
        "# Extracting coronal slice 2\n",
        "cor_2_target_slice = partial(target_slice, targ_pct=0.625)\n",
        "cor_2['targ_ax'] = cor_2['fpath'].map(cor_2_target_slice)\n",
        "cor_2['full_fpath'] = cor_2['fpath'] + '/' + cor_2['targ_ax']\n",
        "cor_2.drop(columns=['fpath', 'targ_ax'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMAlvOXhVRi1"
      },
      "source": [
        "cor_2.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMEedxAjVRmN"
      },
      "source": [
        "# Saving ax_new to a dataframe and then csv, so all steps till here need not be repeated\n",
        "cor_2.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_2.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VKmQQPfVZ6l"
      },
      "source": [
        "## Getting common patients having both axial and coronal slices - limiting analysis to them only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkYMJMgHVRpN"
      },
      "source": [
        "#Load csv dataframe\n",
        "df_ax = pd.read_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/ax.csv')\n",
        "\n",
        "#Load csv dataframe for axial images\n",
        "df_cor_1 = pd.read_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_1.csv')\n",
        "\n",
        "#Load csv dataframe for axial images\n",
        "df_cor_2 = pd.read_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrCFaPQwVniM"
      },
      "source": [
        "## Merging axial and coronal patients having common Patient ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpsRVbNWVRsV"
      },
      "source": [
        "# Keep important columns only\n",
        "ax = df_ax[['PatientID', 'SeriesDescription', 'label', 'full_fpath']]\n",
        "cor_1 = df_cor_1[['PatientID', 'SeriesDescription', 'label', 'full_fpath']]\n",
        "cor_2 = df_cor_2[['PatientID', 'SeriesDescription', 'label', 'full_fpath']]\n",
        "\n",
        "# Get the common patients id in axial and coronal\n",
        "ax_cor_1 = ax.merge(cor_1, how='inner', indicator='True', on='PatientID')\n",
        "\n",
        "ax_cor_1 = ax_cor_1[['PatientID']] #extract only common PatientID\n",
        "\n",
        "# Now merge this with both ax and cor to get common Patients only\n",
        "ax_common = ax.merge(ax_cor_1, how='right', on='PatientID')\n",
        "\n",
        "cor_common_1  = cor_1.merge(ax_cor_1, how='right', on='PatientID')\n",
        "cor_common_2  = cor_2.merge(ax_cor_1, how='right', on='PatientID')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL8f95z0VRvk"
      },
      "source": [
        "# Now write these dataframes to csv, so steps don't need to be repeated and the csv files will be fed to dataloader\n",
        "ax_common.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/ax_common.csv', index=False)\n",
        "cor_common_1.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_common_1.csv', index=False)\n",
        "cor_common_2.to_csv(r'/storage/vs165-projects/Pro00103719 - SIH deep learning/test/cor_common_2.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJXeDnIVVxvO"
      },
      "source": [
        "#### **Number of patients having slices for both axes - axial and coronal in positive and negative cases**\n",
        "| Case | Both Axial & Coronal | \n",
        "| :-- | --: | \n",
        "| Positive | 155 | \n",
        "| Negative | 273 | \n",
        "| Total | 428 | "
      ]
    }
  ]
}